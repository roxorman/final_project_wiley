{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mods import DatabaseConnector \n",
    "import mysql.connector\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of DatabaseConnector\n",
    "myDB = DatabaseConnector('localhost','root','root','final_project')\n",
    "directory = r\"C:\\Users\\marno\\Wiley Edge\\Final_Project\\Code\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of table names and file paths\n",
    "def get_csv_files(directory: str) -> dict[str, str]:\n",
    "    tables = {}\n",
    "    # For each file in a directory, add the file name (excluding the extension) and the file path to the dictionary\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".csv\"):\n",
    "            table_name = file.split(\".\")[0]\n",
    "            file_path = os.path.join(directory, file).replace(\"\\\\\", \"/\")\n",
    "            tables[table_name] = file_path\n",
    "    return tables\n",
    "\n",
    "\n",
    "# Function to populate each table in the database by using the csv files in the directory.\n",
    "def load_data_to_table(csv_file_path, table_name, myDB):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        myDB.connect()\n",
    "                \n",
    "        # Build the SQL query\n",
    "        query = f'LOAD DATA LOCAL INFILE \"{csv_file_path}\" INTO TABLE {table_name} FIELDS TERMINATED BY \",\" ENCLOSED BY \\'\"\\' IGNORE 1 ROWS'\n",
    "\n",
    "        # check if table is already populated\n",
    "        update_query = f\"SELECT COUNT(*) FROM {table_name}\"\n",
    "        result = myDB.execute_query(update_query)\n",
    "        \n",
    "        # If the table is not populated, load the data\n",
    "        if result[0][0] == 0:\n",
    "            myDB.update_query(query)\n",
    "            print(f\"Data from {csv_file_path} loaded into {table_name} successfully.\")\n",
    "        else:\n",
    "            print(f\"Table {table_name} is already populated.\")\n",
    "\n",
    "        print(f\"Data from {csv_file_path} loaded into {table_name} successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        myDB.close_connection()\n",
    "        \n",
    "# Implement the function for each table to load all the data\n",
    "def load_all_data():\n",
    "    for table_name, file_path in get_csv_files(directory).items():\n",
    "        load_data_to_table(file_path, table_name, myDB)\n",
    "    \n",
    "    \n",
    "def import_data():\n",
    "    for table_name in get_csv_files(directory).keys():\n",
    "        myDB.import_data(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database\n",
      "Data from customers imported successfully.\n",
      "Connected to database\n",
      "Data from geolocation imported successfully.\n",
      "Connected to database\n",
      "Data from orders imported successfully.\n",
      "Connected to database\n",
      "Data from order_items imported successfully.\n",
      "Connected to database\n",
      "Data from order_payments imported successfully.\n",
      "Connected to database\n",
      "Data from order_reviews imported successfully.\n",
      "Connected to database\n",
      "Data from products imported successfully.\n",
      "Connected to database\n",
      "Data from product_category_translation imported successfully.\n",
      "Connected to database\n",
      "Data from sellers imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers.csv updated successfully.\n",
      "geolocation.csv updated successfully.\n",
      "orders.csv updated successfully.\n",
      "order_items.csv updated successfully.\n",
      "order_payments.csv updated successfully.\n",
      "order_reviews.csv updated successfully.\n",
      "products.csv updated successfully.\n",
      "product_category_translation.csv updated successfully.\n",
      "sellers.csv updated successfully.\n"
     ]
    }
   ],
   "source": [
    "def get_dataframes():\n",
    "    return myDB.dataframes\n",
    "\n",
    "def update_csv_files(dataframes_dict, directory_path):\n",
    "\n",
    "    # Iterate through the dictionary\n",
    "    for title, dataframe in dataframes_dict.items():\n",
    "        # Construct the CSV file path\n",
    "        csv_file_path = os.path.join(directory_path, f'{title}.csv')\n",
    "\n",
    "        # Check if the CSV file already exists\n",
    "        if os.path.isfile(csv_file_path):\n",
    "            # If it exists, update the CSV file with the new dataframe\n",
    "            dataframe.to_csv(csv_file_path, index=False)\n",
    "            print(f'{title}.csv updated successfully.')\n",
    "        else:\n",
    "            # If it doesn't exist, create a new CSV file\n",
    "            dataframe.to_csv(csv_file_path, index=False)\n",
    "            print(f'{title}.csv created successfully.')\n",
    "            \n",
    "update_csv_files(get_dataframes(), directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace the Portuguese category names with English names\n",
    "def replace_category_names(products_df, translations_df):\n",
    "    # Merge the Products table with the translations table based on the product category name\n",
    "    merged_df = pd.merge(products_df, translations_df, on='product_category_name', how='left')\n",
    "\n",
    "    # Replace the original category name column with the English names\n",
    "    merged_df['product_category_name'] = merged_df['english_category_name']\n",
    "\n",
    "    # Drop the redundant translated column\n",
    "    merged_df = merged_df.drop('english_category_name', axis=1)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Call the function to replace category names\n",
    "updated_products_df = replace_category_names(myDB.dataframes['products'], myDB.dataframes['product_category_translation'])\n",
    "\n",
    "# remove carriage returns from the product_category_name column\n",
    "updated_products_df['product_category_name'] = updated_products_df['product_category_name'].str.replace('\\r', '')\n",
    "\n",
    "# replace the product dataframe in the dictionary with the updated dataframe\n",
    "myDB.dataframes['products'] = updated_products_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers.csv updated successfully.\n",
      "geolocation.csv updated successfully.\n",
      "orders.csv updated successfully.\n",
      "order_items.csv updated successfully.\n",
      "order_payments.csv updated successfully.\n",
      "order_reviews.csv updated successfully.\n",
      "products.csv updated successfully.\n",
      "product_category_translation.csv updated successfully.\n",
      "sellers.csv updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Update the products csv file with the new dataframe\n",
    "\n",
    "update_csv_files(get_dataframes(), directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers.csv updated successfully.\n",
      "geolocation.csv updated successfully.\n",
      "orders.csv updated successfully.\n",
      "order_items.csv updated successfully.\n",
      "order_payments.csv updated successfully.\n",
      "order_reviews.csv updated successfully.\n",
      "products.csv updated successfully.\n",
      "product_category_translation.csv updated successfully.\n",
      "sellers.csv updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# add a new column in geolocations table to store the full state name instead of the abbreviation\n",
    "# get dictionary of state abbreviations and full names\n",
    "def get_state_dict():\n",
    "    return {\n",
    "        'AC': 'Acre',\n",
    "        'AL': 'Alagoas',\n",
    "        'AP': 'Amapá',\n",
    "        'AM': 'Amazonas',\n",
    "        'BA': 'Bahia',\n",
    "        'CE': 'Ceará',\n",
    "        'DF': 'Distrito Federal',\n",
    "        'ES': 'Espírito Santo',\n",
    "        'GO': 'Goiás',\n",
    "        'MA': 'Maranhão',\n",
    "        'MT': 'Mato Grosso',\n",
    "        'MS': 'Mato Grosso do Sul',\n",
    "        'MG': 'Minas Gerais',\n",
    "        'PA': 'Pará',\n",
    "        'PB': 'Paraíba',\n",
    "        'PR': 'Paraná',\n",
    "        'PE': 'Pernambuco',\n",
    "        'PI': 'Piauí',\n",
    "        'RJ': 'Rio de Janeiro',\n",
    "        'RN': 'Rio Grande do Norte',\n",
    "        'RS': 'Rio Grande do Sul',\n",
    "        'RO': 'Rondônia',\n",
    "        'RR': 'Roraima',\n",
    "        'SC': 'Santa Catarina',\n",
    "        'SP': 'São Paulo',\n",
    "        'SE': 'Sergipe',\n",
    "        'TO': 'Tocantins'\n",
    "    }\n",
    "    \n",
    "# Create a new column in the geolocation dataframe to store the full state name\n",
    "def add_state_name(geolocation_df):\n",
    "    # Get the state dictionary\n",
    "    state_dict = get_state_dict()\n",
    "\n",
    "    # Create a new column in the dataframe to store the full state name\n",
    "    geolocation_df['state_name'] = geolocation_df['state'].map(state_dict)\n",
    "\n",
    "    return geolocation_df\n",
    "\n",
    "# Call the function to add the state name column\n",
    "updated_geolocation_df = add_state_name(myDB.dataframes['geolocation'])\n",
    "\n",
    "# update the csv file with the new dataframe\n",
    "myDB.dataframes['geolocation'] = updated_geolocation_df\n",
    "\n",
    "update_csv_files(get_dataframes(), directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marno\\AppData\\Local\\Temp\\ipykernel_50632\\1054106570.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  myDB.dataframes['orders']['delivery_time'] = myDB.dataframes['orders']['delivery_time'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers.csv updated successfully.\n",
      "geolocation.csv updated successfully.\n",
      "orders.csv updated successfully.\n",
      "order_items.csv updated successfully.\n",
      "order_payments.csv updated successfully.\n",
      "order_reviews.csv updated successfully.\n",
      "products.csv updated successfully.\n",
      "product_category_translation.csv updated successfully.\n",
      "sellers.csv updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# add a new column to the orders table to see the time taken between order purchase timestamp and order delivered\n",
    "def add_delivery_time(orders_df):\n",
    "    # Convert the purchase and delivery timestamps to datetime\n",
    "    orders_df['order_purchase_timestamp'] = pd.to_datetime(orders_df['order_purchase_timestamp'])\n",
    "    orders_df['order_delivered_customer_date'] = pd.to_datetime(orders_df['order_delivered_customer_date'])\n",
    "\n",
    "    # Calculate the time taken to deliver the order\n",
    "    orders_df['delivery_time'] = orders_df['order_delivered_customer_date'] - orders_df['order_purchase_timestamp']\n",
    "\n",
    "    # Convert the time taken to days\n",
    "    orders_df['delivery_time'] = orders_df['delivery_time'].dt.days\n",
    "\n",
    "    return orders_df\n",
    "\n",
    "# Call the function to add the delivery time column\n",
    "updated_orders_df = add_delivery_time(myDB.dataframes['orders'])\n",
    "\n",
    "\n",
    "# update the csv file with the new dataframe\n",
    "myDB.dataframes['orders'] = updated_orders_df\n",
    "\n",
    "\n",
    "# count null values in in delivery_time column\n",
    "myDB.dataframes['orders']['delivery_time'].isnull().sum()\n",
    "# remove rows with null values in delivery_time column\n",
    "myDB.dataframes['orders'] = myDB.dataframes['orders'][myDB.dataframes['orders']['delivery_time'].notna()]\n",
    "# make delivery_time column an integer\n",
    "myDB.dataframes['orders']['delivery_time'] = myDB.dataframes['orders']['delivery_time'].astype(int)\n",
    "# update the csv file with the new dataframe\n",
    "update_csv_files(get_dataframes(), directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
